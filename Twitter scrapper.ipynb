{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5ac4bb-eacb-4f39-bb00-3f33cbf530a9",
   "metadata": {},
   "source": [
    "# Twitter Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724291d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad8204-63a2-4792-b0c1-5f5a0abffe02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## For Week 2: With misogyny terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dccab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"snscrape --jsonl --max-results 1000 twitter-search 'bitch' > bitch-tweets.json\")\n",
    "os.system(\"snscrape --jsonl --max-results 1000 twitter-search 'misandry' > misandry-tweets.json\")\n",
    "os.system(\"snscrape --jsonl --max-results 1000 twitter-search 'rape' > rape-tweets.json\")\n",
    "os.system(\"snscrape --jsonl --max-results 1000 twitter-search 'harassment' > harassment-tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56660a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the json generated from the CLI commands above and creates a pandas dataframe\n",
    "bitch_tweets_df = pd.read_json('data/bitch-tweets.json', lines=True)\n",
    "bitch_tweets_df['keyword'] = 'bitch'\n",
    "misandry_tweets_df = pd.read_json('data/misandry-tweets.json', lines=True)\n",
    "misandry_tweets_df['keyword'] = 'misandry'\n",
    "rape_tweets_df = pd.read_json('data/rape-tweets.json', lines=True)\n",
    "rape_tweets_df['keyword'] = 'rape'\n",
    "harassment_tweets_df = pd.read_json('data/harassment-tweets.json', lines=True)\n",
    "harassment_tweets_df['keyword'] = 'harassment'\n",
    "\n",
    "# Now append them together\n",
    "tweets_df = bitch_tweets_df.append(misandry_tweets_df, ignore_index=True).append(rape_tweets_df, ignore_index=True).append(harassment_tweets_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af01861-b0e0-4a8a-ab51-24cbbc83f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4507570c",
   "metadata": {},
   "source": [
    "## For Week 3: From CNN, BBC and Fox news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf32b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list1 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:CNN').get_items()): #declare a username \n",
    "    if i>1000: #number of tweets you want to scrape\n",
    "        break\n",
    "    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username]) #declare the attributes to be returned\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5795b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list to append tweet data \n",
    "tweets_list2 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:BBC').get_items()): #declare a username \n",
    "    if i>1000: #number of tweets you want to scrape\n",
    "        break\n",
    "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username]) #declare the attributes to be returned\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Text', 'Media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f049eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list to append tweet data \n",
    "tweets_list3 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:FoxNews').get_items()): #declare a username \n",
    "    if i>1000: #number of tweets you want to scrape\n",
    "        break\n",
    "    tweets_list3.append([tweet.date, tweet.id, tweet.content, tweet.user.username]) #declare the attributes to be returned\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df3 = pd.DataFrame(tweets_list3, columns=['Datetime', 'Tweet Id', 'Text', 'Media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2653755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86188\\AppData\\Local\\Temp\\ipykernel_17084\\2757352255.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tweets_df = tweets_df1.append(tweets_df2, ignore_index=True).append(tweets_df3, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "tweets_df = tweets_df1.append(tweets_df2, ignore_index=True).append(tweets_df3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "406afe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "week3_3media_df = tweets_df.to_csv('./data/week3_3media_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d7e69",
   "metadata": {},
   "source": [
    "### For dynamic topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbdf9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_since = []\n",
    "for month in range(1,13):\n",
    "    dates_since.append('2021-{:02d}-04'.format(month))\n",
    "\n",
    "dates_until = []\n",
    "for month in range(1,13):\n",
    "    dates_until.append('2021-{:02d}-10'.format(month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b6e8c5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m tweets_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m month, since, until \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(dates_since,dates_until)):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sntwitter\u001b[38;5;241m.\u001b[39mTwitterSearchScraper(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom:CNN since:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m until:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(since,until))\u001b[38;5;241m.\u001b[39mget_items()): \u001b[38;5;66;03m#declare a username \u001b[39;00m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "tweets_list = []\n",
    "for since, until in zip(dates_since,dates_until):\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:CNN since:{} until:{}'.format(since,until)).get_items()): #declare a username \n",
    "        if i > 500:\n",
    "            break\n",
    "        tweets_list.append([tweet.date, tweet.content]) #declare the attributes to be returned\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16955b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-09 23:30:09+00:00</td>\n",
       "      <td>Brad Rukstales, CEO of Cogensia, a Chicago mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-09 23:14:06+00:00</td>\n",
       "      <td>President Trump is expected to be represented ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-09 23:00:03+00:00</td>\n",
       "      <td>Republican US Rep. Mary Miller of Illinois iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-09 22:45:02+00:00</td>\n",
       "      <td>News outlets are publishing more videos, photo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-09 22:27:03+00:00</td>\n",
       "      <td>\"We must understand well and reflect, learn ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5777</th>\n",
       "      <td>2021-12-04 01:25:15+00:00</td>\n",
       "      <td>Pacific Gas &amp;amp; Electric must pay $125 milli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>2021-12-04 01:11:34+00:00</td>\n",
       "      <td>US special operations forces in northeastern S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>2021-12-04 00:54:16+00:00</td>\n",
       "      <td>A 50-year-old man tried to pass off a silicone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>2021-12-04 00:45:03+00:00</td>\n",
       "      <td>A repeat hate crime offender has been sentence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>2021-12-04 00:35:54+00:00</td>\n",
       "      <td>South Africa's Covid-19 cases have nearly quad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5782 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime  \\\n",
       "0    2021-01-09 23:30:09+00:00   \n",
       "1    2021-01-09 23:14:06+00:00   \n",
       "2    2021-01-09 23:00:03+00:00   \n",
       "3    2021-01-09 22:45:02+00:00   \n",
       "4    2021-01-09 22:27:03+00:00   \n",
       "...                        ...   \n",
       "5777 2021-12-04 01:25:15+00:00   \n",
       "5778 2021-12-04 01:11:34+00:00   \n",
       "5779 2021-12-04 00:54:16+00:00   \n",
       "5780 2021-12-04 00:45:03+00:00   \n",
       "5781 2021-12-04 00:35:54+00:00   \n",
       "\n",
       "                                                   Text  \n",
       "0     Brad Rukstales, CEO of Cogensia, a Chicago mar...  \n",
       "1     President Trump is expected to be represented ...  \n",
       "2     Republican US Rep. Mary Miller of Illinois iss...  \n",
       "3     News outlets are publishing more videos, photo...  \n",
       "4     \"We must understand well and reflect, learn ho...  \n",
       "...                                                 ...  \n",
       "5777  Pacific Gas &amp; Electric must pay $125 milli...  \n",
       "5778  US special operations forces in northeastern S...  \n",
       "5779  A 50-year-old man tried to pass off a silicone...  \n",
       "5780  A repeat hate crime offender has been sentence...  \n",
       "5781  South Africa's Covid-19 cases have nearly quad...  \n",
       "\n",
       "[5782 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b437481",
   "metadata": {},
   "outputs": [],
   "source": [
    "week3_arch_cnn_df = tweets_df.to_csv('./data/week3_arch_cnn_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e40e5",
   "metadata": {},
   "source": [
    "## For Week 4-5: From 10 media with 5 of them being left-leaned and 5 being right-leaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83fa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_list = ['CNN','thedailybeast','jacobin','democracynow','HuffPost','FoxNews','BreitbartNews','NRO','amspectator','NYPostOpinion']\n",
    "tweets_list = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for media in media_list:\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:{}'.format(media)).get_items()): #declare a username \n",
    "        if i>1000: #number of tweets you want to scrape\n",
    "            break\n",
    "        tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username]) #declare the attributes to be returned\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'ID','Text', 'Media'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7bc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "week45_10media_df = tweets_df.to_csv('./data/week45_10media_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
