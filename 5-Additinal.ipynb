{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724291d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For ML\n",
    "import sklearn\n",
    "# import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.neural_network\n",
    "import sklearn.decomposition\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np #arrays\n",
    "import matplotlib.pyplot as plt #Plots\n",
    "import scipy as sp #for interp\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cf32b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GaussianNB()\n",
    "clf2 = sklearn.svm.SVC(kernel = 'linear', probability = True) \n",
    "clf3 = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "clf4 = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "#Symbolists\n",
    "clf5 = sklearn.tree.DecisionTreeClassifier()\n",
    "clf6 = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "#Connectionists\n",
    "clf7 = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "#Ensemble\n",
    "clf8 = sklearn.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5795b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [clf1,clf2,clf3,clf4,clf5,clf6,clf7,clf8]\n",
    "clf_names = ['naive bayes','SVC','KNN','logistic','decision tree','random forest','MLP','gradient boosting']\n",
    "\n",
    "def get_results(train,test):\n",
    "    tables = []\n",
    "    group_n = len(set(train['category']))\n",
    "    for clf in clfs:\n",
    "        clf.fit(np.stack(train['vect'], axis=0), train['category'])\n",
    "        tables.append(lucem_illud.evaluateClassifier(clf, test))\n",
    "    tables = pd.concat(tables)\n",
    "    tables['clf_names'] = np.repeat(clf_names,group_n)\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f049eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for: comp.sys.mac.hardware\n",
      "Loading data for: comp.windows.x\n",
      "Loading data for: misc.forsale\n",
      "Loading data for: rec.autos\n",
      "Converting to vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MySoftware\\python310\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "D:\\MySoftware\\python310\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading senate data\n",
      "Converting to vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MySoftware\\python310\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "D:\\MySoftware\\python310\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading senator: Kennedy\n",
      "Loading senator: Kerry\n",
      "Loading senator: Klobuchar\n",
      "Loading senator: Kohl\n",
      "Loading senator: Kyl\n",
      "Converting to vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MySoftware\\python310\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "D:\\MySoftware\\python310\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Spam\n",
      "Loading Ham\n",
      "Converting to vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MySoftware\\python310\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "D:\\MySoftware\\python310\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "dfTrain_n, dfTest_n = sklearn.model_selection.train_test_split(lucem_illud.loadNewsGroups(), test_size=.2)\n",
    "dfTrain_ss, dfTest_ss = sklearn.model_selection.train_test_split(lucem_illud.loadSenateSmall(), test_size=.2)\n",
    "dfTrain_sl, dfTest_sl = sklearn.model_selection.train_test_split(lucem_illud.loadSenateLarge(), test_size=.2)\n",
    "dfTrain_sp, dfTest_sp = sklearn.model_selection.train_test_split(lucem_illud.loadSpam(), test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406afe74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>clf_names</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.068085</td>\n",
       "      <td>0.922244</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.755912</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.155319</td>\n",
       "      <td>0.812798</td>\n",
       "      <td>0.629921</td>\n",
       "      <td>0.530731</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.110638</td>\n",
       "      <td>0.858319</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.682583</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.138298</td>\n",
       "      <td>0.793355</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.638096</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.969341</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.917668</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.072340</td>\n",
       "      <td>0.896460</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.741136</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.944116</td>\n",
       "      <td>0.843972</td>\n",
       "      <td>0.816227</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.080851</td>\n",
       "      <td>0.882885</td>\n",
       "      <td>0.906780</td>\n",
       "      <td>0.781517</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.193617</td>\n",
       "      <td>0.576843</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.324853</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.423404</td>\n",
       "      <td>0.566167</td>\n",
       "      <td>0.277512</td>\n",
       "      <td>0.253974</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.453191</td>\n",
       "      <td>0.535710</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.281491</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.278723</td>\n",
       "      <td>0.535870</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.313827</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.971363</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.908070</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.887026</td>\n",
       "      <td>0.836538</td>\n",
       "      <td>0.727018</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.816233</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.082979</td>\n",
       "      <td>0.876910</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.777147</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.091489</td>\n",
       "      <td>0.866471</td>\n",
       "      <td>0.798077</td>\n",
       "      <td>0.677669</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.140426</td>\n",
       "      <td>0.805697</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.548376</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.161702</td>\n",
       "      <td>0.818435</td>\n",
       "      <td>0.668966</td>\n",
       "      <td>0.578692</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.146809</td>\n",
       "      <td>0.794132</td>\n",
       "      <td>0.792793</td>\n",
       "      <td>0.618512</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.942074</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.839443</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.859320</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.672965</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.102128</td>\n",
       "      <td>0.902377</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.711934</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.102128</td>\n",
       "      <td>0.847814</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.728156</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.969341</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.917668</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.068085</td>\n",
       "      <td>0.899207</td>\n",
       "      <td>0.855769</td>\n",
       "      <td>0.754693</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.070213</td>\n",
       "      <td>0.929217</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.788063</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.082979</td>\n",
       "      <td>0.883640</td>\n",
       "      <td>0.892562</td>\n",
       "      <td>0.774697</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.780898</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.854603</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.666025</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.144681</td>\n",
       "      <td>0.860638</td>\n",
       "      <td>0.677019</td>\n",
       "      <td>0.624403</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.832134</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.713882</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Error_Rate       AUC  Precision  Average_Precision  \\\n",
       "Category                                                                    \n",
       "comp.windows.x           0.068085  0.922244   0.811966           0.755912   \n",
       "comp.sys.mac.hardware    0.155319  0.812798   0.629921           0.530731   \n",
       "rec.autos                0.110638  0.858319   0.792000           0.682583   \n",
       "misc.forsale             0.138298  0.793355   0.841584           0.638096   \n",
       "comp.windows.x           0.021277  0.969341   0.952381           0.917668   \n",
       "comp.sys.mac.hardware    0.072340  0.896460   0.839623           0.741136   \n",
       "rec.autos                0.059574  0.944116   0.843972           0.816227   \n",
       "misc.forsale             0.080851  0.882885   0.906780           0.781517   \n",
       "comp.windows.x           0.193617  0.576843   0.850000           0.324853   \n",
       "comp.sys.mac.hardware    0.423404  0.566167   0.277512           0.253974   \n",
       "rec.autos                0.453191  0.535710   0.296296           0.281491   \n",
       "misc.forsale             0.278723  0.535870   0.560000           0.313827   \n",
       "comp.windows.x           0.023404  0.971363   0.935185           0.908070   \n",
       "comp.sys.mac.hardware    0.076596  0.887026   0.836538           0.727018   \n",
       "rec.autos                0.059574  0.946667   0.839161           0.816233   \n",
       "misc.forsale             0.082979  0.876910   0.913043           0.777147   \n",
       "comp.windows.x           0.091489  0.866471   0.798077           0.677669   \n",
       "comp.sys.mac.hardware    0.140426  0.805697   0.681818           0.548376   \n",
       "rec.autos                0.161702  0.818435   0.668966           0.578692   \n",
       "misc.forsale             0.146809  0.794132   0.792793           0.618512   \n",
       "comp.windows.x           0.042553  0.942074   0.897196           0.839443   \n",
       "comp.sys.mac.hardware    0.093617  0.859320   0.803922           0.672965   \n",
       "rec.autos                0.102128  0.902377   0.754967           0.711934   \n",
       "misc.forsale             0.102128  0.847814   0.890909           0.728156   \n",
       "comp.windows.x           0.021277  0.969341   0.952381           0.917668   \n",
       "comp.sys.mac.hardware    0.068085  0.899207   0.855769           0.754693   \n",
       "rec.autos                0.070213  0.929217   0.828571           0.788063   \n",
       "misc.forsale             0.082979  0.883640   0.892562           0.774697   \n",
       "comp.windows.x           0.059574  0.914155   0.866667           0.780898   \n",
       "comp.sys.mac.hardware    0.095745  0.854603   0.801980           0.666025   \n",
       "rec.autos                0.144681  0.860638   0.677019           0.624403   \n",
       "misc.forsale             0.108511  0.832134   0.902913           0.713882   \n",
       "\n",
       "                         Recall          clf_names  \n",
       "Category                                            \n",
       "comp.windows.x         0.904762        naive bayes  \n",
       "comp.sys.mac.hardware  0.754717        naive bayes  \n",
       "rec.autos              0.792000        naive bayes  \n",
       "misc.forsale           0.634328        naive bayes  \n",
       "comp.windows.x         0.952381                SVC  \n",
       "comp.sys.mac.hardware  0.839623                SVC  \n",
       "rec.autos              0.952000                SVC  \n",
       "misc.forsale           0.798507                SVC  \n",
       "comp.windows.x         0.161905                KNN  \n",
       "comp.sys.mac.hardware  0.547170                KNN  \n",
       "rec.autos              0.512000                KNN  \n",
       "misc.forsale           0.104478                KNN  \n",
       "comp.windows.x         0.961905           logistic  \n",
       "comp.sys.mac.hardware  0.820755           logistic  \n",
       "rec.autos              0.960000           logistic  \n",
       "misc.forsale           0.783582           logistic  \n",
       "comp.windows.x         0.790476      decision tree  \n",
       "comp.sys.mac.hardware  0.707547      decision tree  \n",
       "rec.autos              0.776000      decision tree  \n",
       "misc.forsale           0.656716      decision tree  \n",
       "comp.windows.x         0.914286      random forest  \n",
       "comp.sys.mac.hardware  0.773585      random forest  \n",
       "rec.autos              0.912000      random forest  \n",
       "misc.forsale           0.731343      random forest  \n",
       "comp.windows.x         0.952381                MLP  \n",
       "comp.sys.mac.hardware  0.839623                MLP  \n",
       "rec.autos              0.928000                MLP  \n",
       "misc.forsale           0.805970                MLP  \n",
       "comp.windows.x         0.866667  gradient boosting  \n",
       "comp.sys.mac.hardware  0.764151  gradient boosting  \n",
       "rec.autos              0.872000  gradient boosting  \n",
       "misc.forsale           0.694030  gradient boosting  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(dfTrain_n,dfTest_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a18e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>clf_names</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.850468</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.776872</td>\n",
       "      <td>0.787671</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.850468</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.828158</td>\n",
       "      <td>0.913265</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992149</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.125731</td>\n",
       "      <td>0.871960</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.789434</td>\n",
       "      <td>0.856164</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.125731</td>\n",
       "      <td>0.871960</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.856478</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984299</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.991473</td>\n",
       "      <td>0.986395</td>\n",
       "      <td>0.982562</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.991473</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.990568</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.029240</td>\n",
       "      <td>0.969248</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.949812</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.029240</td>\n",
       "      <td>0.969248</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.961603</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.997449</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.997449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997822</td>\n",
       "      <td>0.994898</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Error_Rate       AUC  Precision  Average_Precision    Recall  \\\n",
       "Category                                                                 \n",
       "Obama       0.140351  0.850468   0.871212           0.776872  0.787671   \n",
       "Clinton     0.140351  0.850468   0.852381           0.828158  0.913265   \n",
       "Obama       0.005848  0.993151   1.000000           0.992149  0.986301   \n",
       "Clinton     0.005848  0.993151   0.989899           0.989899  1.000000   \n",
       "Obama       0.125731  0.871960   0.850340           0.789434  0.856164   \n",
       "Clinton     0.125731  0.871960   0.892308           0.856478  0.887755   \n",
       "Obama       0.011696  0.986301   1.000000           0.984299  0.972603   \n",
       "Clinton     0.011696  0.986301   0.980000           0.980000  1.000000   \n",
       "Obama       0.008772  0.991473   0.986395           0.982562  0.993151   \n",
       "Clinton     0.008772  0.991473   0.994872           0.990568  0.989796   \n",
       "Obama       0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Clinton     0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Obama       0.029240  0.969248   0.972222           0.949812  0.958904   \n",
       "Clinton     0.029240  0.969248   0.969697           0.961603  0.979592   \n",
       "Obama       0.002924  0.997449   0.993197           0.993197  1.000000   \n",
       "Clinton     0.002924  0.997449   1.000000           0.997822  0.994898   \n",
       "\n",
       "                  clf_names  \n",
       "Category                     \n",
       "Obama           naive bayes  \n",
       "Clinton         naive bayes  \n",
       "Obama                   SVC  \n",
       "Clinton                 SVC  \n",
       "Obama                   KNN  \n",
       "Clinton                 KNN  \n",
       "Obama              logistic  \n",
       "Clinton            logistic  \n",
       "Obama         decision tree  \n",
       "Clinton       decision tree  \n",
       "Obama         random forest  \n",
       "Clinton       random forest  \n",
       "Obama                   MLP  \n",
       "Clinton                 MLP  \n",
       "Obama     gradient boosting  \n",
       "Clinton   gradient boosting  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(dfTrain_ss,dfTest_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f027a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>clf_names</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.248399</td>\n",
       "      <td>0.767904</td>\n",
       "      <td>0.658052</td>\n",
       "      <td>0.645209</td>\n",
       "      <td>0.937677</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.080666</td>\n",
       "      <td>0.697376</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.430637</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.051216</td>\n",
       "      <td>0.755537</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.550234</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.133163</td>\n",
       "      <td>0.781154</td>\n",
       "      <td>0.722973</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.629412</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.057618</td>\n",
       "      <td>0.744056</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.501431</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.020487</td>\n",
       "      <td>0.980067</td>\n",
       "      <td>0.969359</td>\n",
       "      <td>0.962031</td>\n",
       "      <td>0.985836</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.977919</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.943700</td>\n",
       "      <td>0.958763</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977561</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.982021</td>\n",
       "      <td>0.976331</td>\n",
       "      <td>0.954018</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988935</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.149808</td>\n",
       "      <td>0.850907</td>\n",
       "      <td>0.818919</td>\n",
       "      <td>0.766945</td>\n",
       "      <td>0.858357</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.053777</td>\n",
       "      <td>0.841013</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.625652</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.032010</td>\n",
       "      <td>0.871434</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.717916</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.148528</td>\n",
       "      <td>0.803177</td>\n",
       "      <td>0.642105</td>\n",
       "      <td>0.522265</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.033291</td>\n",
       "      <td>0.894092</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.715960</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.037132</td>\n",
       "      <td>0.965377</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.926781</td>\n",
       "      <td>0.991501</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.019206</td>\n",
       "      <td>0.927104</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.863409</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966341</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.975320</td>\n",
       "      <td>0.970238</td>\n",
       "      <td>0.939250</td>\n",
       "      <td>0.958824</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.006402</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944674</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>0.995623</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.994845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990971</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.999287</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988935</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.033291</td>\n",
       "      <td>0.966648</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>0.943275</td>\n",
       "      <td>0.966006</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.960994</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.897316</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977561</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.020487</td>\n",
       "      <td>0.974170</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.916945</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.986940</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.965678</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>0.995623</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.994845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990971</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Error_Rate       AUC  Precision  Average_Precision    Recall  \\\n",
       "Category                                                                  \n",
       "Kennedy      0.248399  0.767904   0.658052           0.645209  0.937677   \n",
       "Kyl          0.080666  0.697376   0.886364           0.430637  0.402062   \n",
       "Kohl         0.051216  0.755537   0.976190           0.550234  0.512500   \n",
       "Kerry        0.133163  0.781154   0.722973           0.535714  0.629412   \n",
       "Klobuchar    0.057618  0.744056   0.909091           0.501431  0.493827   \n",
       "Kennedy      0.020487  0.980067   0.969359           0.962031  0.985836   \n",
       "Kyl          0.007682  0.977919   0.978947           0.943700  0.958763   \n",
       "Kohl         0.002561  0.987500   1.000000           0.977561  0.975000   \n",
       "Kerry        0.011524  0.982021   0.976331           0.954018  0.970588   \n",
       "Klobuchar    0.001280  0.993827   1.000000           0.988935  0.987654   \n",
       "Kennedy      0.149808  0.850907   0.818919           0.766945  0.858357   \n",
       "Kyl          0.053777  0.841013   0.839506           0.625652  0.701031   \n",
       "Kohl         0.032010  0.871434   0.923077           0.717916  0.750000   \n",
       "Kerry        0.148528  0.803177   0.642105           0.522265  0.717647   \n",
       "Klobuchar    0.033291  0.894092   0.866667           0.715960  0.802469   \n",
       "Kennedy      0.037132  0.965377   0.930851           0.926781  0.991501   \n",
       "Kyl          0.019206  0.927104   0.988095           0.863409  0.855670   \n",
       "Kohl         0.003841  0.981250   1.000000           0.966341  0.962500   \n",
       "Kerry        0.015365  0.975320   0.970238           0.939250  0.958824   \n",
       "Klobuchar    0.006402  0.969136   1.000000           0.944674  0.938272   \n",
       "Kennedy      0.002561  0.997415   0.997167           0.995623  0.997167   \n",
       "Kyl          0.001280  0.994845   1.000000           0.990971  0.989691   \n",
       "Kohl         0.001280  0.999287   0.987654           0.987654  1.000000   \n",
       "Kerry        0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Klobuchar    0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Kennedy      0.001280  0.998832   0.997175           0.997175  1.000000   \n",
       "Kyl          0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Kohl         0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Kerry        0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Klobuchar    0.001280  0.993827   1.000000           0.988935  0.987654   \n",
       "Kennedy      0.033291  0.966648   0.960563           0.943275  0.966006   \n",
       "Kyl          0.014085  0.960994   0.957447           0.897316  0.927835   \n",
       "Kohl         0.002561  0.987500   1.000000           0.977561  0.975000   \n",
       "Kerry        0.020487  0.974170   0.942529           0.916945  0.964706   \n",
       "Klobuchar    0.003841  0.986940   0.987500           0.965678  0.975309   \n",
       "Kennedy      0.002561  0.997415   0.997167           0.995623  0.997167   \n",
       "Kyl          0.001280  0.994845   1.000000           0.990971  0.989691   \n",
       "Kohl         0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Kerry        0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Klobuchar    0.001280  0.999286   0.987805           0.987805  1.000000   \n",
       "\n",
       "                   clf_names  \n",
       "Category                      \n",
       "Kennedy          naive bayes  \n",
       "Kyl              naive bayes  \n",
       "Kohl             naive bayes  \n",
       "Kerry            naive bayes  \n",
       "Klobuchar        naive bayes  \n",
       "Kennedy                  SVC  \n",
       "Kyl                      SVC  \n",
       "Kohl                     SVC  \n",
       "Kerry                    SVC  \n",
       "Klobuchar                SVC  \n",
       "Kennedy                  KNN  \n",
       "Kyl                      KNN  \n",
       "Kohl                     KNN  \n",
       "Kerry                    KNN  \n",
       "Klobuchar                KNN  \n",
       "Kennedy             logistic  \n",
       "Kyl                 logistic  \n",
       "Kohl                logistic  \n",
       "Kerry               logistic  \n",
       "Klobuchar           logistic  \n",
       "Kennedy        decision tree  \n",
       "Kyl            decision tree  \n",
       "Kohl           decision tree  \n",
       "Kerry          decision tree  \n",
       "Klobuchar      decision tree  \n",
       "Kennedy        random forest  \n",
       "Kyl            random forest  \n",
       "Kohl           random forest  \n",
       "Kerry          random forest  \n",
       "Klobuchar      random forest  \n",
       "Kennedy                  MLP  \n",
       "Kyl                      MLP  \n",
       "Kohl                     MLP  \n",
       "Kerry                    MLP  \n",
       "Klobuchar                MLP  \n",
       "Kennedy    gradient boosting  \n",
       "Kyl        gradient boosting  \n",
       "Kohl       gradient boosting  \n",
       "Kerry      gradient boosting  \n",
       "Klobuchar  gradient boosting  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(dfTrain_sl,dfTest_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9cab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>clf_names</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.169343</td>\n",
       "      <td>0.799406</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.382493</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.169343</td>\n",
       "      <td>0.799406</td>\n",
       "      <td>0.951644</td>\n",
       "      <td>0.935949</td>\n",
       "      <td>0.843911</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.705395</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.423607</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.705395</td>\n",
       "      <td>0.907790</td>\n",
       "      <td>0.906623</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.672552</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.355595</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.672552</td>\n",
       "      <td>0.898574</td>\n",
       "      <td>0.897271</td>\n",
       "      <td>0.972556</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.122628</td>\n",
       "      <td>0.596324</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.297961</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.122628</td>\n",
       "      <td>0.596324</td>\n",
       "      <td>0.876320</td>\n",
       "      <td>0.876233</td>\n",
       "      <td>0.996569</td>\n",
       "      <td>logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.737505</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>0.420131</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.737505</td>\n",
       "      <td>0.919142</td>\n",
       "      <td>0.916107</td>\n",
       "      <td>0.955403</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.103650</td>\n",
       "      <td>0.744980</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.441349</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.103650</td>\n",
       "      <td>0.744980</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.918293</td>\n",
       "      <td>0.960549</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.770104</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.462383</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.770104</td>\n",
       "      <td>0.929648</td>\n",
       "      <td>0.925876</td>\n",
       "      <td>0.951973</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.124088</td>\n",
       "      <td>0.599511</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.291189</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.124088</td>\n",
       "      <td>0.599511</td>\n",
       "      <td>0.877273</td>\n",
       "      <td>0.877093</td>\n",
       "      <td>0.993139</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Error_Rate       AUC  Precision  Average_Precision    Recall  \\\n",
       "Category                                                                 \n",
       "spam        0.169343  0.799406   0.458333           0.382493  0.754902   \n",
       "not spam    0.169343  0.799406   0.951644           0.935949  0.843911   \n",
       "spam        0.102190  0.705395   0.785714           0.423607  0.431373   \n",
       "not spam    0.102190  0.705395   0.907790           0.906623  0.979417   \n",
       "spam        0.116788  0.672552   0.703704           0.355595  0.372549   \n",
       "not spam    0.116788  0.672552   0.898574           0.897271  0.972556   \n",
       "spam        0.122628  0.596324   0.909091           0.297961  0.196078   \n",
       "not spam    0.122628  0.596324   0.876320           0.876233  0.996569   \n",
       "spam        0.109489  0.737505   0.670886           0.420131  0.519608   \n",
       "not spam    0.109489  0.737505   0.919142           0.916107  0.955403   \n",
       "spam        0.103650  0.744980   0.701299           0.441349  0.529412   \n",
       "not spam    0.103650  0.744980   0.921053           0.918293  0.960549   \n",
       "spam        0.102190  0.770104   0.681818           0.462383  0.588235   \n",
       "not spam    0.102190  0.770104   0.929648           0.925876  0.951973   \n",
       "spam        0.124088  0.599511   0.840000           0.291189  0.205882   \n",
       "not spam    0.124088  0.599511   0.877273           0.877093  0.993139   \n",
       "\n",
       "                  clf_names  \n",
       "Category                     \n",
       "spam            naive bayes  \n",
       "not spam        naive bayes  \n",
       "spam                    SVC  \n",
       "not spam                SVC  \n",
       "spam                    KNN  \n",
       "not spam                KNN  \n",
       "spam               logistic  \n",
       "not spam           logistic  \n",
       "spam          decision tree  \n",
       "not spam      decision tree  \n",
       "spam          random forest  \n",
       "not spam      random forest  \n",
       "spam                    MLP  \n",
       "not spam                MLP  \n",
       "spam      gradient boosting  \n",
       "not spam  gradient boosting  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(dfTrain_sp,dfTest_sp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
